# Unsupervised-Learning
ðŸ”¹ 1. Performing Principal Component Analysis (PCA)
This notebook implements PCA to reduce dimensionality while retaining the variance in a dataset. The workflow includes:

Data standardization

Applying PCA using sklearn

Visualizing the explained variance ratio

Plotting principal components for insight into data structure

PCA is used here to simplify high-dimensional data for visualization and modeling efficiency.

ðŸ”¹ 2. Performing Linear Discriminant Analysis (LDA)
Implements LDA for dimensionality reduction with a focus on maximizing class separability. The process involves:

Splitting the dataset into training and testing sets

Fitting LinearDiscriminantAnalysis from sklearn

Reducing feature dimensions and visualizing class distributions

This notebook is targeted at supervised problems where class labels guide the dimensionality reduction.

ðŸ”¹ 3. Implementing Common Techniques of Dimensionality Reduction
Showcases a combined implementation of several popular dimensionality reduction techniques. It includes:

Standard scaling

Comparison of PCA and LDA

Potential integration of techniques like t-SNE 

The goal is to compare effectiveness of various methods in reducing feature space while maintaining information integrity.

